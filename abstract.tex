\begin{abstract}
Most products in the domain of improving the visually impaired textual understanding focus on the direct translation or dictation of text that is in front of a user. Seldom focus on any type of textual understanding that goes beyond literal translation. In this report, we are documenting the implementation of a novel wearable device that allows the visually impaired to have a better understanding of the textual world around them by having a system learn a textual understanding for them and then providing more significant and natural feedback based on a userâ€™s semantic queries regarding the text at their gaze.This document includes the requirements, design, use cases, risk tables, workflow and our projected development timeline for this device we are developing. This report also provides a way for us to review our progress and justify decisions we make as we advance in the development phase.
\end{abstract}
