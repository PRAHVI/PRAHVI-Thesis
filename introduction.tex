\chapter{Introduction}

\section{Motivation}

Communication is the hallmark of our interactions as humans, occurring across different media, platforms, and entire paradigms. Much of the information we consume on a daily basis is provided by very specialized media, such as a newspaper or a billboard, that caters to only one specific sense, such as vision. This presents a particular challenge for individuals with sensory disabilities. Every day people absorb visual, sonic, and touch information from their surroundings. The visually impaired rely on a heightened sense of sound and touch to obtain information and are hindered from being able to easily obtain data from visual texts, such as posters, newspaper, fliers, etc. This hindrance not only affects their ability to obtain important textual information, such as warning or caution signs, but it also statistically raises the likelihood of unemployment.

\section{Current Solutions}

The Braille alphabet has been one of the most common aids in bridging the gap between textual information for people with visual disabilities. However, Braille presents significant issues around its usability, portability, and adoption. In terms of usability, Braille depends on text being translated and presented on a medium that the user can touch. This assumes the user has some indication of where the text is located, for example, on a sign. Although Braille reading systems exist, these systems are typically very bulky and must be tethered to a personal computer to operate, hindering portability. Most importantly, Braille suffers from a low literacy rate within the visually impaired community because it requires teachers with specialized training, a luxury that is not always available at public schools in the U.S.
	
There are many products on the market that serve as an alternative to Braille. One example is the FingerReader by the MIT Media Lab, an electronic device that dictates the text the user touches in a document. However it can only read 12-point font that the user can physically touch. Another example, the OrCam MyEye, is a dedicated wearable headset that also performs live text dictation and can is marketed as having the capability to read text within the user's reach. However, it is priced at \$2,500 which is outside the price range of many users in this segment. More significantly, its gestural input requires that the user has some visual capability to find the text. Although the FingerReader and OrCam products make significant strides toward usability and effectiveness, they still fall short of being truly practical for most users.

\section{New Solution}

There is a general issues we identified with all the current solutions involve the total cost, usability, and practicality of the system. With this system we seek to address the shortcomings of each, while incorporating their advantages. We have designed an assistive Optical Character Recognition (OCR) system consisting of a portable headset that captures a feed of the user's surroundings, a front-end mobile application that performs live OCR of the text within this feed, and a back-end framework for building a model of textual understanding. This system is capable of reading aloud the key points of the text the user is positioned to “gaze” at and allow the user to manipulate the translation in real-time. As with OrCam, we chose a headset form-factor to serve as the basis for capturing the user's surroundings so that the system's input follows the user's head movement in a natural, unobstructive manner. By using computer vision, we allow the user to focus on text both close as a handheld newspaper and as far as a billboard. With a mobile phone for processing, rather than dedicated hardware, we address another key shortcoming of the current solutions by keeping the cost of the device down and allowing the system to build a model for better dictation in the future. With this system, we hope to address one of the biggest daily challenges of individuals who are visually impaired, a very underserved segment of our society.