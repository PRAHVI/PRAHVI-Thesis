\chapter{Introduction}

\section{Motivation}

Communication is the hallmark of our interactions as humans, occurring across different media, platforms, and entire paradigms. Much of the information we consume on a daily basis is provided in very specialized media, such as a newspaper or a billboard, that cater to only one specific sense, such as vision. This presents a particular challenge for individuals with sensory disabilities. Every day people absorb visual, sonic, and touch information from their surroundings. The visually impaired rely on a heightened sense of sound and touch to obtain information and are hindered from being able to easily obtain data from visual texts, such as posters, newspaper, fliers, etc. This hindrance not only affects the ability to obtain important textual information, such as warning or caution signs, but it also statistically raises the likelihood of unemployment.

\section{Current Solutions}

The Braille alphabet has been one of the most common aids in bridging the gap between textual information and people with visual disabilities. However, one of the problems with Braille is that it depends on text being translated and printed on a medium that the user can touch. More importantly, Braille suffers from a low literacy rate within the visually impaired community because it requires teachers with specialized training, a luxury that is not always available at public schools in the U.S.
	
There are many products on the market that serve as an alternative to Braille. One example is the FingerReader by the MIT Media Lab, an electronic device that dictates the text the user touches in a document. However it can only read font that is of 12-point that the user can physically touch. Another example, the OrCam MyEye, is a dedicated headset that also performs live text dictation. However, it is priced at \$2,500 and still requires a gesture input that assumes the user has some visual capability. There is a general issue with both products directly feeding the user everything from the text content. People who are not visually impaired can skim the content or skip around to get a brief idea of the content; the visually impaired must finish listening to the entire passage to understand the whole content.

\section{New Solution}

To address this problem, we are proposing to design an assistive Optical Character Recognition (OCR) system consisting of a portable headset that captures a feed of the user’s surroundings, a front-end mobile application that performs live OCR of the text within this feed, and a back-end framework for building a model of textual understanding. This system is capable of reading aloud the key points of the text the user is positioned to “gaze” at. By using haptics and computer vision, we address the shortcomings of current solutions by allowing the user to focus on text both as near as a handheld newspaper and as far as a billboard. By using a mobile phone for processing, rather than dedicated hardware, we address another key shortcoming of the current solutions by keeping the cost of the device down and allowing the system to build a model for better dictation in the future. With this system, we hope to address one of the biggest daily challenges of individuals who are visually impaired, a very underserved segment of our society.